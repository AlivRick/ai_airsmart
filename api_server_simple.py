#!/usr/bin/env python3
"""
API Server cho PDF Chatbot sá»­ dá»¥ng FastAPI
Cho phÃ©p cÃ¡c á»©ng dá»¥ng khÃ¡c gá»i API Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i
Version Ä‘Æ¡n giáº£n sá»­ dá»¥ng requests Ä‘á»ƒ gá»i Gemini API
"""

from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import os
import tempfile
import shutil
import requests
import json
from typing import Optional
from dotenv import load_dotenv
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import pickle

# Import cÃ¡c thÆ° viá»‡n LangChain
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

class SimplePDFChatbot:
    """
    Lá»›p PDFChatbot Ä‘Æ¡n giáº£n sá»­ dá»¥ng requests Ä‘á»ƒ gá»i Gemini API
    """
    
    def __init__(self, pdf_path: str):
        """
        Khá»Ÿi táº¡o chatbot vá»›i Ä‘Æ°á»ng dáº«n file PDF
        """
        # Load biáº¿n mÃ´i trÆ°á»ng
        load_dotenv()
        
        # Kiá»ƒm tra API key
        self.gemini_api_key = os.getenv('GEMINI_API_KEY')
        if not self.gemini_api_key:
            raise ValueError("GEMINI_API_KEY khÃ´ng tÃ¬m tháº¥y trong file .env")
        
        # Cáº¥u hÃ¬nh Gemini API
        self.model_name = os.getenv('GEMINI_MODEL', 'gemini-1.5-flash')
        self.api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.model_name}:generateContent?key={self.gemini_api_key}"
        
        self.pdf_path = pdf_path
        self.text_chunks = []
        self.vectorizer = None
        self.tfidf_matrix = None
        
        # Khá»Ÿi táº¡o cÃ¡c thÃ nh pháº§n
        self._setup_components()
    
    def _setup_components(self):
        """
        Thiáº¿t láº­p cÃ¡c thÃ nh pháº§n cá»§a chatbot
        """
        print("ğŸ”„ Äang khá»Ÿi táº¡o chatbot vá»›i Gemini...")
        
        # 1. Äá»c file PDF
        print("ğŸ“– Äang Ä‘á»c file PDF...")
        documents = self._load_pdf()
        
        # 2. Chia nhá» vÄƒn báº£n
        print("âœ‚ï¸ Äang chia nhá» vÄƒn báº£n...")
        self.text_chunks = self._split_text(documents)
        
        # 3. Táº¡o vector embeddings vá»›i TF-IDF
        print("ğŸ”¢ Äang táº¡o vector embeddings vá»›i TF-IDF...")
        self._create_tfidf_vectors()
        
        print("âœ… Chatbot Ä‘Ã£ sáºµn sÃ ng!")
    
    def _load_pdf(self):
        """
        Äá»c ná»™i dung tá»« file PDF
        """
        if not os.path.exists(self.pdf_path):
            raise FileNotFoundError(f"File PDF khÃ´ng tÃ¬m tháº¥y: {self.pdf_path}")
        
        loader = PyPDFLoader(self.pdf_path)
        documents = loader.load()
        
        print(f"ğŸ“„ ÄÃ£ Ä‘á»c {len(documents)} trang tá»« file PDF")
        return documents
    
    def _split_text(self, documents):
        """
        Chia nhá» vÄƒn báº£n thÃ nh cÃ¡c chunk
        """
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        
        text_chunks = text_splitter.split_documents(documents)
        print(f"âœ‚ï¸ ÄÃ£ chia thÃ nh {len(text_chunks)} chunks")
        return text_chunks
    
    def _create_tfidf_vectors(self):
        """
        Táº¡o TF-IDF vectors tá»« text chunks
        """
        texts = [chunk.page_content for chunk in self.text_chunks]
        
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            stop_words='english',
            ngram_range=(1, 2)
        )
        
        self.tfidf_matrix = self.vectorizer.fit_transform(texts)
        print(f"ğŸ”¢ ÄÃ£ táº¡o TF-IDF vectors vá»›i {self.tfidf_matrix.shape[1]} features")
    
    def _retrieve_relevant_chunks(self, question: str, k: int = 3):
        """
        Truy xuáº¥t cÃ¡c chunks cÃ³ liÃªn quan Ä‘áº¿n cÃ¢u há»i
        """
        question_vector = self.vectorizer.transform([question])
        similarities = cosine_similarity(question_vector, self.tfidf_matrix).flatten()
        top_indices = similarities.argsort()[-k:][::-1]
        
        relevant_chunks = []
        for idx in top_indices:
            if similarities[idx] > 0.1:
                relevant_chunks.append(self.text_chunks[idx].page_content)
        
        return relevant_chunks
    
    def _call_gemini_api(self, prompt: str) -> str:
        """
        Gá»i Gemini API Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i
        """
        try:
            headers = {
                'Content-Type': 'application/json',
            }
            
            payload = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.3,
                    "topK": 1,
                    "topP": 1,
                    "maxOutputTokens": 2048,
                }
            }
            
            response = requests.post(self.api_url, headers=headers, json=payload)
            
            if response.status_code == 200:
                data = response.json()
                if 'candidates' in data and len(data['candidates']) > 0:
                    return data['candidates'][0]['content']['parts'][0]['text']
                else:
                    return "Xin lá»—i, khÃ´ng thá»ƒ táº¡o cÃ¢u tráº£ lá»i."
            else:
                return f"Lá»—i API: {response.status_code} - {response.text}"
                
        except Exception as e:
            return f"Lá»—i khi gá»i Gemini API: {str(e)}"
    
    def ask_question(self, question: str) -> dict:
        """
        Äáº·t cÃ¢u há»i cho chatbot
        """
        try:
            relevant_chunks = self._retrieve_relevant_chunks(question)
            
            if not relevant_chunks:
                return {
                    "answer": "TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trong tÃ i liá»‡u Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i nÃ y.",
                    "source_count": 0
                }
            
            context = "\n\n".join(relevant_chunks)
            
            prompt = f"""Dá»±a trÃªn thÃ´ng tin sau Ä‘Ã¢y tá»« tÃ i liá»‡u PDF, hÃ£y tráº£ lá»i cÃ¢u há»i báº±ng tiáº¿ng Viá»‡t má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  chi tiáº¿t.
Náº¿u thÃ´ng tin khÃ´ng Ä‘á»§ Ä‘á»ƒ tráº£ lá»i, hÃ£y nÃ³i ráº±ng báº¡n khÃ´ng tÃ¬m tháº¥y thÃ´ng tin cáº§n thiáº¿t trong tÃ i liá»‡u.

THÃ”NG TIN Tá»ª TÃ€I LIá»†U:
{context}

CÃ‚U Há»I: {question}

HÃ£y tráº£ lá»i má»™t cÃ¡ch rÃµ rÃ ng vÃ  dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p:"""
            
            answer = self._call_gemini_api(prompt)
            
            return {
                "answer": answer,
                "source_count": len(relevant_chunks)
            }
            
        except Exception as e:
            return {
                "answer": f"Xin lá»—i, cÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ cÃ¢u há»i: {str(e)}",
                "source_count": 0
            }

app = FastAPI(
    title="PDF Chatbot API",
    description="API Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i dá»±a trÃªn ná»™i dung PDF sá»­ dá»¥ng Gemini AI",
    version="1.0.0"
)

# Cho phÃ©p CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global chatbot instance
chatbot = None
current_pdf_path = None

class QuestionRequest(BaseModel):
    question: str

class QuestionResponse(BaseModel):
    answer: str
    source_count: int
    status: str

class StatusResponse(BaseModel):
    status: str
    message: str
    pdf_loaded: bool
    pdf_path: Optional[str] = None
    chunks_count: Optional[int] = None

@app.get("/")
async def root():
    """
    Endpoint gá»‘c Ä‘á»ƒ kiá»ƒm tra API
    """
    return {
        "message": "PDF Chatbot API Ä‘ang hoáº¡t Ä‘á»™ng",
        "version": "1.0.0",
        "endpoints": {
            "POST /upload-pdf": "Upload file PDF",
            "POST /ask": "Äáº·t cÃ¢u há»i",
            "GET /status": "Kiá»ƒm tra tráº¡ng thÃ¡i",
            "GET /health": "Health check"
        }
    }

@app.get("/health")
async def health_check():
    """
    Health check endpoint
    """
    return {"status": "healthy", "message": "API Ä‘ang hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng"}

@app.get("/status", response_model=StatusResponse)
async def get_status():
    """
    Kiá»ƒm tra tráº¡ng thÃ¡i cá»§a chatbot
    """
    global chatbot, current_pdf_path
    
    if chatbot is None:
        return StatusResponse(
            status="not_initialized",
            message="Chatbot chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o. HÃ£y upload file PDF trÆ°á»›c.",
            pdf_loaded=False
        )
    
    return StatusResponse(
        status="ready",
        message="Chatbot Ä‘Ã£ sáºµn sÃ ng tráº£ lá»i cÃ¢u há»i",
        pdf_loaded=True,
        pdf_path=current_pdf_path,
        chunks_count=len(chatbot.text_chunks) if chatbot.text_chunks else 0
    )

@app.post("/load-pdf", response_model=StatusResponse)
async def load_existing_pdf(pdf_path: str):
    """
    Load file PDF Ä‘Ã£ cÃ³ sáºµn trong há»‡ thá»‘ng
    """
    global chatbot, current_pdf_path
    
    try:
        if not os.path.exists(pdf_path):
            raise HTTPException(status_code=404, detail="File PDF khÃ´ng tá»“n táº¡i")
        
        chatbot = SimplePDFChatbot(pdf_path)
        current_pdf_path = pdf_path
        
        return StatusResponse(
            status="success",
            message=f"ÄÃ£ load file {pdf_path} thÃ nh cÃ´ng",
            pdf_loaded=True,
            pdf_path=current_pdf_path,
            chunks_count=len(chatbot.text_chunks)
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi load file PDF: {str(e)}")

@app.post("/ask", response_model=QuestionResponse)
async def ask_question(request: QuestionRequest):
    """
    Äáº·t cÃ¢u há»i cho chatbot
    """
    global chatbot
    
    if chatbot is None:
        raise HTTPException(
            status_code=400, 
            detail="Chatbot chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o. HÃ£y upload file PDF trÆ°á»›c."
        )
    
    if not request.question.strip():
        raise HTTPException(status_code=400, detail="CÃ¢u há»i khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng")
    
    try:
        result = chatbot.ask_question(request.question)
        
        return QuestionResponse(
            answer=result["answer"],
            source_count=result["source_count"],
            status="success"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi xá»­ lÃ½ cÃ¢u há»i: {str(e)}")

if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘              ğŸš€ PDF CHATBOT API SERVER           â•‘
    â•‘                                                   â•‘
    â•‘  API Endpoints:                                   â•‘
    â•‘  â€¢ POST /load-pdf - Load file PDF cÃ³ sáºµn         â•‘
    â•‘  â€¢ POST /ask - Äáº·t cÃ¢u há»i                       â•‘
    â•‘  â€¢ GET /status - Kiá»ƒm tra tráº¡ng thÃ¡i             â•‘
    â•‘  â€¢ GET /health - Health check                    â•‘
    â•‘                                                   â•‘
    â•‘  Server sáº½ cháº¡y táº¡i: http://localhost:8000       â•‘
    â•‘  API Docs táº¡i: http://localhost:8000/docs        â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Load file PDF máº·c Ä‘á»‹nh náº¿u cÃ³
    default_pdf = "sample.pdf"
    if os.path.exists(default_pdf):
        try:
            chatbot = SimplePDFChatbot(default_pdf)
            current_pdf_path = default_pdf
            print(f"âœ… ÄÃ£ load file PDF máº·c Ä‘á»‹nh: {default_pdf}")
        except Exception as e:
            print(f"âš ï¸ KhÃ´ng thá»ƒ load file PDF máº·c Ä‘á»‹nh: {e}")
    
    # Cháº¡y server
    uvicorn.run(app, host="0.0.0.0", port=8000)