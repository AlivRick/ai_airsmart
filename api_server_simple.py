#!/usr/bin/env python3
"""
API Server cho PDF Chatbot s·ª≠ d·ª•ng FastAPI
Cho ph√©p c√°c ·ª©ng d·ª•ng kh√°c g·ªçi API ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi
Version ƒë∆°n gi·∫£n s·ª≠ d·ª•ng requests ƒë·ªÉ g·ªçi Gemini API
"""

from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import os
import tempfile
import shutil
import requests
import json
from typing import Optional
from dotenv import load_dotenv
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import pickle

# Import c√°c th∆∞ vi·ªán LangChain
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

class SimplePDFChatbot:
    """
    L·ªõp PDFChatbot ƒë∆°n gi·∫£n s·ª≠ d·ª•ng requests ƒë·ªÉ g·ªçi Gemini API
    """
    
    def __init__(self, pdf_path: str):
        """
        Kh·ªüi t·∫°o chatbot v·ªõi ƒë∆∞·ªùng d·∫´n file PDF
        """
        # Load bi·∫øn m√¥i tr∆∞·ªùng
        load_dotenv()
        
        # Ki·ªÉm tra API key
        self.gemini_api_key = os.getenv('GEMINI_API_KEY')
        if not self.gemini_api_key:
            raise ValueError("GEMINI_API_KEY kh√¥ng t√¨m th·∫•y trong file .env")
        
        # C·∫•u h√¨nh Gemini API
        self.model_name = os.getenv('GEMINI_MODEL', 'gemini-1.5-flash')
        self.api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.model_name}:generateContent?key={self.gemini_api_key}"
        
        self.pdf_path = pdf_path
        self.text_chunks = []
        self.vectorizer = None
        self.tfidf_matrix = None
        
        # Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn
        self._setup_components()
    
    def _setup_components(self):
        """
        Thi·∫øt l·∫≠p c√°c th√†nh ph·∫ßn c·ªßa chatbot
        """
        print("üîÑ ƒêang kh·ªüi t·∫°o chatbot v·ªõi Gemini...")
        
        # 1. ƒê·ªçc file PDF
        print("üìñ ƒêang ƒë·ªçc file PDF...")
        documents = self._load_pdf()
        
        # 2. Chia nh·ªè vƒÉn b·∫£n
        print("‚úÇÔ∏è ƒêang chia nh·ªè vƒÉn b·∫£n...")
        self.text_chunks = self._split_text(documents)
        
        # 3. T·∫°o vector embeddings v·ªõi TF-IDF
        print("üî¢ ƒêang t·∫°o vector embeddings v·ªõi TF-IDF...")
        self._create_tfidf_vectors()
        
        print("‚úÖ Chatbot ƒë√£ s·∫µn s√†ng!")
    
    def _load_pdf(self):
        """
        ƒê·ªçc n·ªôi dung t·ª´ file PDF
        """
        if not os.path.exists(self.pdf_path):
            raise FileNotFoundError(f"File PDF kh√¥ng t√¨m th·∫•y: {self.pdf_path}")
        
        loader = PyPDFLoader(self.pdf_path)
        documents = loader.load()
        
        print(f"üìÑ ƒê√£ ƒë·ªçc {len(documents)} trang t·ª´ file PDF")
        return documents
    
    def _split_text(self, documents):
        """
        Chia nh·ªè vƒÉn b·∫£n th√†nh c√°c chunk
        """
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        
        text_chunks = text_splitter.split_documents(documents)
        print(f"‚úÇÔ∏è ƒê√£ chia th√†nh {len(text_chunks)} chunks")
        return text_chunks
    
    def _create_tfidf_vectors(self):
        """
        T·∫°o TF-IDF vectors t·ª´ text chunks
        """
        texts = [chunk.page_content for chunk in self.text_chunks]
        
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            stop_words='english',
            ngram_range=(1, 2)
        )
        
        self.tfidf_matrix = self.vectorizer.fit_transform(texts)
        print(f"üî¢ ƒê√£ t·∫°o TF-IDF vectors v·ªõi {self.tfidf_matrix.shape[1]} features")
    
    def _retrieve_relevant_chunks(self, question: str, k: int = 3):
        """
        Truy xu·∫•t c√°c chunks c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi
        """
        question_vector = self.vectorizer.transform([question])
        similarities = cosine_similarity(question_vector, self.tfidf_matrix).flatten()
        top_indices = similarities.argsort()[-k:][::-1]
        
        relevant_chunks = []
        for idx in top_indices:
            if similarities[idx] > 0.1:
                relevant_chunks.append(self.text_chunks[idx].page_content)
        
        return relevant_chunks
    
    def _call_gemini_api(self, prompt: str) -> str:
        """
        G·ªçi Gemini API ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi
        """
        try:
            headers = {
                'Content-Type': 'application/json',
            }
            
            payload = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.3,
                    "topK": 1,
                    "topP": 1,
                    "maxOutputTokens": 2048,
                }
            }
            
            response = requests.post(self.api_url, headers=headers, json=payload)
            
            if response.status_code == 200:
                data = response.json()
                if 'candidates' in data and len(data['candidates']) > 0:
                    return data['candidates'][0]['content']['parts'][0]['text']
                else:
                    return "Xin l·ªói, kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi."
            else:
                return f"L·ªói API: {response.status_code} - {response.text}"
                
        except Exception as e:
            return f"L·ªói khi g·ªçi Gemini API: {str(e)}"
    
    def ask_question(self, question: str) -> dict:
        """
        ƒê·∫∑t c√¢u h·ªèi cho chatbot
        """
        try:
            relevant_chunks = self._retrieve_relevant_chunks(question)
            
            if not relevant_chunks:
                return {
                    "answer": "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong t√†i li·ªáu ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y.",
                    "source_count": 0
                }
            
            context = "\n\n".join(relevant_chunks)
            
            prompt = f"""D·ª±a tr√™n th√¥ng tin sau ƒë√¢y t·ª´ t√†i li·ªáu PDF, h√£y tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ti·∫øng Vi·ªát m·ªôt c√°ch ch√≠nh x√°c v√† chi ti·∫øt.
N·∫øu th√¥ng tin kh√¥ng ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi, h√£y n√≥i r·∫±ng b·∫°n kh√¥ng t√¨m th·∫•y th√¥ng tin c·∫ßn thi·∫øt trong t√†i li·ªáu.

TH√îNG TIN T·ª™ T√ÄI LI·ªÜU:
{context}

C√ÇU H·ªéI: {question}

H√£y tr·∫£ l·ªùi m·ªôt c√°ch r√µ r√†ng v√† d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p:"""
            
            answer = self._call_gemini_api(prompt)
            
            return {
                "answer": answer,
                "source_count": len(relevant_chunks)
            }
            
        except Exception as e:
            return {
                "answer": f"Xin l·ªói, c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}",
                "source_count": 0
            }

app = FastAPI(
    title="PDF Chatbot API",
    description="API ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n n·ªôi dung PDF s·ª≠ d·ª•ng Gemini AI",
    version="1.0.0"
)

# Cho ph√©p CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global chatbot instance
chatbot = None
current_pdf_path = None

class QuestionRequest(BaseModel):
    question: str

class QuestionResponse(BaseModel):
    answer: str
    source_count: int
    status: str

class StatusResponse(BaseModel):
    status: str
    message: str
    pdf_loaded: bool
    pdf_path: Optional[str] = None
    chunks_count: Optional[int] = None

@app.get("/")
async def root():
    """
    Endpoint g·ªëc ƒë·ªÉ ki·ªÉm tra API
    """
    return {
        "message": "PDF Chatbot API ƒëang ho·∫°t ƒë·ªông",
        "version": "1.0.0",
        "endpoints": {
            "POST /upload-pdf": "Upload file PDF",
            "POST /ask": "ƒê·∫∑t c√¢u h·ªèi",
            "GET /status": "Ki·ªÉm tra tr·∫°ng th√°i",
            "GET /health": "Health check"
        }
    }

@app.get("/health")
async def health_check():
    """
    Health check endpoint
    """
    return {"status": "healthy", "message": "API ƒëang ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng"}

@app.get("/status", response_model=StatusResponse)
async def get_status():
    """
    Ki·ªÉm tra tr·∫°ng th√°i c·ªßa chatbot
    """
    global chatbot, current_pdf_path
    
    if chatbot is None:
        return StatusResponse(
            status="not_initialized",
            message="Chatbot ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o. H√£y upload file PDF tr∆∞·ªõc.",
            pdf_loaded=False
        )
    
    return StatusResponse(
        status="ready",
        message="Chatbot ƒë√£ s·∫µn s√†ng tr·∫£ l·ªùi c√¢u h·ªèi",
        pdf_loaded=True,
        pdf_path=current_pdf_path,
        chunks_count=len(chatbot.text_chunks) if chatbot.text_chunks else 0
    )

@app.post("/load-pdf", response_model=StatusResponse)
async def load_existing_pdf(pdf_path: str):
    """
    Load file PDF ƒë√£ c√≥ s·∫µn trong h·ªá th·ªëng
    """
    global chatbot, current_pdf_path
    
    try:
        if not os.path.exists(pdf_path):
            raise HTTPException(status_code=404, detail="File PDF kh√¥ng t·ªìn t·∫°i")
        
        chatbot = SimplePDFChatbot(pdf_path)
        current_pdf_path = pdf_path
        
        return StatusResponse(
            status="success",
            message=f"ƒê√£ load file {pdf_path} th√†nh c√¥ng",
            pdf_loaded=True,
            pdf_path=current_pdf_path,
            chunks_count=len(chatbot.text_chunks)
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi load file PDF: {str(e)}")

@app.post("/ask", response_model=QuestionResponse)
async def ask_question(request: QuestionRequest):
    """
    ƒê·∫∑t c√¢u h·ªèi cho chatbot
    """
    global chatbot
    
    if chatbot is None:
        raise HTTPException(
            status_code=400, 
            detail="Chatbot ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o. H√£y upload file PDF tr∆∞·ªõc."
        )
    
    if not request.question.strip():
        raise HTTPException(status_code=400, detail="C√¢u h·ªèi kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng")
    
    try:
        result = chatbot.ask_question(request.question)
        
        return QuestionResponse(
            answer=result["answer"],
            source_count=result["source_count"],
            status="success"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}")

if __name__ == "__main__":
    print("""
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë              üöÄ PDF CHATBOT API SERVER           ‚ïë
    ‚ïë                                                   ‚ïë
    ‚ïë  API Endpoints:                                   ‚ïë
    ‚ïë  ‚Ä¢ POST /load-pdf - Load file PDF c√≥ s·∫µn         ‚ïë
    ‚ïë  ‚Ä¢ POST /ask - ƒê·∫∑t c√¢u h·ªèi                       ‚ïë
    ‚ïë  ‚Ä¢ GET /status - Ki·ªÉm tra tr·∫°ng th√°i             ‚ïë
    ‚ïë  ‚Ä¢ GET /health - Health check                    ‚ïë
    ‚ïë                                                   ‚ïë
    ‚ïë  Server s·∫Ω ch·∫°y t·∫°i: http://localhost:8000       ‚ïë
    ‚ïë  API Docs t·∫°i: http://localhost:8000/docs        ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    # Load file PDF m·∫∑c ƒë·ªãnh n·∫øu c√≥
    default_pdf = "sample.pdf"
    if os.path.exists(default_pdf):
        try:
            chatbot = SimplePDFChatbot(default_pdf)
            current_pdf_path = default_pdf
            print(f"‚úÖ ƒê√£ load file PDF m·∫∑c ƒë·ªãnh: {default_pdf}")
        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ load file PDF m·∫∑c ƒë·ªãnh: {e}")
    
    # Ch·∫°y server
    uvicorn.run(app, host="0.0.0.0", port=8000)