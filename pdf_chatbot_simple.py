#!/usr/bin/env python3
"""
PDF Chatbot sá»­ dá»¥ng LangChain vÃ  Google Gemini API
TÃ¡c giáº£: GitHub Copilot
MÃ´ táº£: Chatbot cÃ³ thá»ƒ Ä‘á»c file PDF vÃ  tráº£ lá»i cÃ¢u há»i dá»±a trÃªn ná»™i dung file (sá»­ dá»¥ng Gemini miá»…n phÃ­)
"""

import os
import sys
import json
import requests
from typing import List
from dotenv import load_dotenv
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import pickle

# Import cÃ¡c thÆ° viá»‡n LangChain
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

class GeminiPDFChatbot:
    """
    Lá»›p PDFChatbot sá»­ dá»¥ng Google Gemini API Ä‘á»ƒ xá»­ lÃ½ file PDF vÃ  tráº£ lá»i cÃ¢u há»i
    """
    
    def __init__(self, pdf_path: str):
        """
        Khá»Ÿi táº¡o chatbot vá»›i Ä‘Æ°á»ng dáº«n file PDF
        
        Args:
            pdf_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file PDF
        """
        # Load biáº¿n mÃ´i trÆ°á»ng
        load_dotenv()
        
        # Kiá»ƒm tra API key
        self.gemini_api_key = os.getenv('GEMINI_API_KEY')
        if not self.gemini_api_key:
            raise ValueError("GEMINI_API_KEY khÃ´ng tÃ¬m tháº¥y trong file .env")
        
        # Cáº¥u hÃ¬nh Gemini API
        self.model_name = os.getenv('GEMINI_MODEL', 'gemini-1.5-flash')
        self.api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.model_name}:generateContent?key={self.gemini_api_key}"
        
        self.pdf_path = pdf_path
        self.text_chunks = []
        self.vectorizer = None
        self.tfidf_matrix = None
        
        # Khá»Ÿi táº¡o cÃ¡c thÃ nh pháº§n
        self._setup_components()
    
    def _setup_components(self):
        """
        Thiáº¿t láº­p cÃ¡c thÃ nh pháº§n cá»§a chatbot
        """
        print("ğŸ”„ Äang khá»Ÿi táº¡o chatbot vá»›i Gemini...")
        
        # 1. Äá»c file PDF
        print("ğŸ“– Äang Ä‘á»c file PDF...")
        documents = self._load_pdf()
        
        # 2. Chia nhá» vÄƒn báº£n
        print("âœ‚ï¸ Äang chia nhá» vÄƒn báº£n...")
        self.text_chunks = self._split_text(documents)
        
        # 3. Táº¡o vector embeddings vá»›i TF-IDF (miá»…n phÃ­)
        print("ğŸ”¢ Äang táº¡o vector embeddings vá»›i TF-IDF...")
        self._create_tfidf_vectors()
        
        print("âœ… Chatbot Ä‘Ã£ sáºµn sÃ ng!")
    
    def _load_pdf(self) -> List:
        """
        Äá»c ná»™i dung tá»« file PDF
        
        Returns:
            List: Danh sÃ¡ch cÃ¡c document tá»« PDF
        """
        if not os.path.exists(self.pdf_path):
            raise FileNotFoundError(f"File PDF khÃ´ng tÃ¬m tháº¥y: {self.pdf_path}")
        
        loader = PyPDFLoader(self.pdf_path)
        documents = loader.load()
        
        print(f"ğŸ“„ ÄÃ£ Ä‘á»c {len(documents)} trang tá»« file PDF")
        return documents
    
    def _split_text(self, documents: List) -> List:
        """
        Chia nhá» vÄƒn báº£n thÃ nh cÃ¡c chunk
        
        Args:
            documents (List): Danh sÃ¡ch documents tá»« PDF
            
        Returns:
            List: Danh sÃ¡ch cÃ¡c text chunks
        """
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,      # KÃ­ch thÆ°á»›c má»—i chunk
            chunk_overlap=200,    # Äá»™ chá»“ng láº¥p giá»¯a cÃ¡c chunk
            length_function=len,  # HÃ m Ä‘o Ä‘á»™ dÃ i
        )
        
        text_chunks = text_splitter.split_documents(documents)
        print(f"âœ‚ï¸ ÄÃ£ chia thÃ nh {len(text_chunks)} chunks")
        return text_chunks
    
    def _create_tfidf_vectors(self):
        """
        Táº¡o TF-IDF vectors tá»« text chunks (thay tháº¿ cho OpenAI embeddings)
        """
        # Láº¥y ná»™i dung text tá»« chunks
        texts = [chunk.page_content for chunk in self.text_chunks]
        
        # Táº¡o TF-IDF vectorizer
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            stop_words='english',
            ngram_range=(1, 2)
        )
        
        # Fit vÃ  transform texts
        self.tfidf_matrix = self.vectorizer.fit_transform(texts)
        
        print(f"ğŸ”¢ ÄÃ£ táº¡o TF-IDF vectors vá»›i {self.tfidf_matrix.shape[1]} features")
    
    def _retrieve_relevant_chunks(self, question: str, k: int = 3) -> List[str]:
        """
        Truy xuáº¥t cÃ¡c chunks cÃ³ liÃªn quan Ä‘áº¿n cÃ¢u há»i
        
        Args:
            question (str): CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
            k (int): Sá»‘ lÆ°á»£ng chunks cáº§n láº¥y
            
        Returns:
            List[str]: Danh sÃ¡ch cÃ¡c chunks liÃªn quan
        """
        # Vectorize cÃ¢u há»i
        question_vector = self.vectorizer.transform([question])
        
        # TÃ­nh cosine similarity
        similarities = cosine_similarity(question_vector, self.tfidf_matrix).flatten()
        
        # Láº¥y k chunks cÃ³ similarity cao nháº¥t
        top_indices = similarities.argsort()[-k:][::-1]
        
        relevant_chunks = []
        for idx in top_indices:
            if similarities[idx] > 0.1:  # NgÆ°á»¡ng similarity tá»‘i thiá»ƒu
                relevant_chunks.append(self.text_chunks[idx].page_content)
        
        return relevant_chunks
    
    def _call_gemini_api(self, prompt: str) -> str:
        """
        Gá»i Gemini API Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i
        
        Args:
            prompt (str): Prompt Ä‘á»ƒ gá»­i Ä‘áº¿n Gemini
            
        Returns:
            str: CÃ¢u tráº£ lá»i tá»« Gemini
        """
        try:
            headers = {
                'Content-Type': 'application/json',
            }
            
            payload = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.3,
                    "topK": 1,
                    "topP": 1,
                    "maxOutputTokens": 2048,
                }
            }
            
            response = requests.post(self.api_url, headers=headers, json=payload)
            
            if response.status_code == 200:
                data = response.json()
                if 'candidates' in data and len(data['candidates']) > 0:
                    return data['candidates'][0]['content']['parts'][0]['text']
                else:
                    return "Xin lá»—i, khÃ´ng thá»ƒ táº¡o cÃ¢u tráº£ lá»i."
            else:
                return f"Lá»—i API: {response.status_code} - {response.text}"
                
        except Exception as e:
            return f"Lá»—i khi gá»i Gemini API: {str(e)}"
    
    def ask_question(self, question: str) -> dict:
        """
        Äáº·t cÃ¢u há»i cho chatbot
        
        Args:
            question (str): CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
            
        Returns:
            dict: Káº¿t quáº£ bao gá»“m cÃ¢u tráº£ lá»i vÃ  nguá»“n tÃ i liá»‡u
        """
        try:
            # Truy xuáº¥t chunks liÃªn quan
            relevant_chunks = self._retrieve_relevant_chunks(question)
            
            if not relevant_chunks:
                return {
                    "answer": "TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trong tÃ i liá»‡u Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i nÃ y.",
                    "source_count": 0
                }
            
            # Táº¡o ngá»¯ cáº£nh tá»« chunks
            context = "\n\n".join(relevant_chunks)
            
            # Táº¡o prompt cho Gemini
            prompt = f"""Dá»±a trÃªn thÃ´ng tin sau Ä‘Ã¢y tá»« tÃ i liá»‡u PDF, hÃ£y tráº£ lá»i cÃ¢u há»i báº±ng tiáº¿ng Viá»‡t má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  chi tiáº¿t.
Náº¿u thÃ´ng tin khÃ´ng Ä‘á»§ Ä‘á»ƒ tráº£ lá»i, hÃ£y nÃ³i ráº±ng báº¡n khÃ´ng tÃ¬m tháº¥y thÃ´ng tin cáº§n thiáº¿t trong tÃ i liá»‡u.

THÃ”NG TIN Tá»ª TÃ€I LIá»†U:
{context}

CÃ‚U Há»I: {question}

HÃ£y tráº£ lá»i má»™t cÃ¡ch rÃµ rÃ ng vÃ  dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p:"""
            
            # Gá»­i request Ä‘áº¿n Gemini
            answer = self._call_gemini_api(prompt)
            
            return {
                "answer": answer,
                "source_count": len(relevant_chunks)
            }
            
        except Exception as e:
            return {
                "answer": f"Xin lá»—i, cÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ cÃ¢u há»i: {str(e)}",
                "source_count": 0
            }
    
    def save_vectorstore(self, save_path: str):
        """
        LÆ°u vectorstore Ä‘á»ƒ sá»­ dá»¥ng láº¡i
        
        Args:
            save_path (str): ÄÆ°á»ng dáº«n lÆ°u vectorstore
        """
        data = {
            'text_chunks': [chunk.page_content for chunk in self.text_chunks],
            'vectorizer': self.vectorizer,
            'tfidf_matrix': self.tfidf_matrix
        }
        
        with open(save_path, 'wb') as f:
            pickle.dump(data, f)
        
        print(f"ğŸ’¾ ÄÃ£ lÆ°u vectorstore táº¡i: {save_path}")
    
    def load_vectorstore(self, load_path: str):
        """
        Táº£i vectorstore Ä‘Ã£ lÆ°u
        
        Args:
            load_path (str): ÄÆ°á»ng dáº«n vectorstore Ä‘Ã£ lÆ°u
        """
        with open(load_path, 'rb') as f:
            data = pickle.load(f)
        
        self.vectorizer = data['vectorizer']
        self.tfidf_matrix = data['tfidf_matrix']
        
        print(f"ğŸ“‚ ÄÃ£ táº£i vectorstore tá»«: {load_path}")


def print_banner():
    """
    In banner cho á»©ng dá»¥ng
    """
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘              ğŸ¤– PDF CHATBOT                      â•‘
    â•‘        Sá»­ dá»¥ng LangChain & Gemini (MIá»„N PHÃ)     â•‘
    â•‘                                                   â•‘
    â•‘  â€¢ Äá»c file PDF vÃ  tráº£ lá»i cÃ¢u há»i               â•‘
    â•‘  â€¢ GÃµ 'quit' hoáº·c 'exit' Ä‘á»ƒ thoÃ¡t               â•‘
    â•‘  â€¢ GÃµ 'clear' Ä‘á»ƒ xÃ³a mÃ n hÃ¬nh                   â•‘
    â•‘  â€¢ GÃµ 'info' Ä‘á»ƒ xem thÃ´ng tin há»‡ thá»‘ng          â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)


def main():
    """
    HÃ m main Ä‘á»ƒ cháº¡y á»©ng dá»¥ng chatbot
    """
    print_banner()
    
    # ÄÆ°á»ng dáº«n file PDF máº·c Ä‘á»‹nh
    default_pdf_path = "sample.pdf"
    
    # Kiá»ƒm tra xem file PDF cÃ³ tá»“n táº¡i khÃ´ng
    pdf_path = input(f"Nháº­p Ä‘Æ°á»ng dáº«n file PDF (Enter Ä‘á»ƒ sá»­ dá»¥ng '{default_pdf_path}'): ").strip()
    if not pdf_path:
        pdf_path = default_pdf_path
    
    try:
        # Khá»Ÿi táº¡o chatbot
        chatbot = GeminiPDFChatbot(pdf_path)
        
        print("\n" + "="*60)
        print("ğŸ’¬ Báº¯t Ä‘áº§u trÃ² chuyá»‡n! HÃ£y Ä‘áº·t cÃ¢u há»i vá» ná»™i dung PDF...")
        print("="*60)
        
        # VÃ²ng láº·p chat
        while True:
            try:
                # Nháº­n cÃ¢u há»i tá»« ngÆ°á»i dÃ¹ng
                question = input("\nğŸ™‹ Báº¡n: ").strip()
                
                # Kiá»ƒm tra lá»‡nh thoÃ¡t
                if question.lower() in ['quit', 'exit', 'thoÃ¡t']:
                    print("ğŸ‘‹ Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng PDF Chatbot!")
                    break
                
                # Lá»‡nh xÃ³a mÃ n hÃ¬nh
                if question.lower() == 'clear':
                    os.system('clear' if os.name == 'posix' else 'cls')
                    print_banner()
                    continue
                
                # Lá»‡nh xem thÃ´ng tin
                if question.lower() == 'info':
                    print(f"ğŸ“Š ThÃ´ng tin há»‡ thá»‘ng:")
                    print(f"   â€¢ File PDF: {pdf_path}")
                    print(f"   â€¢ Sá»‘ chunks: {len(chatbot.text_chunks)}")
                    print(f"   â€¢ MÃ´ hÃ¬nh: {chatbot.model_name}")
                    print(f"   â€¢ API: Google Gemini (miá»…n phÃ­)")
                    continue
                
                # Bá» qua cÃ¢u há»i trá»‘ng
                if not question:
                    print("âš ï¸ Vui lÃ²ng nháº­p cÃ¢u há»i.")
                    continue
                
                # Xá»­ lÃ½ cÃ¢u há»i
                print("ğŸ¤” Äang suy nghÄ©...")
                result = chatbot.ask_question(question)
                
                # In cÃ¢u tráº£ lá»i
                print(f"\nğŸ¤– Bot: {result['answer']}")
                
                # In thÃ´ng tin nguá»“n
                if result['source_count'] > 0:
                    print(f"\nğŸ“š Nguá»“n: TÃ¬m tháº¥y {result['source_count']} Ä‘oáº¡n vÄƒn liÃªn quan")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng PDF Chatbot!")
                break
            except Exception as e:
                print(f"\nâŒ Lá»—i: {str(e)}")
                continue
    
    except FileNotFoundError as e:
        print(f"âŒ Lá»—i: {str(e)}")
        print("ğŸ’¡ HÃ£y Ä‘áº£m báº£o file PDF tá»“n táº¡i vÃ  Ä‘Æ°á»ng dáº«n chÃ­nh xÃ¡c.")
    except ValueError as e:
        print(f"âŒ Lá»—i cáº¥u hÃ¬nh: {str(e)}")
        print("ğŸ’¡ HÃ£y kiá»ƒm tra file .env vÃ  GEMINI_API_KEY.")
    except Exception as e:
        print(f"âŒ Lá»—i khÃ´ng mong muá»‘n: {str(e)}")


if __name__ == "__main__":
    main()